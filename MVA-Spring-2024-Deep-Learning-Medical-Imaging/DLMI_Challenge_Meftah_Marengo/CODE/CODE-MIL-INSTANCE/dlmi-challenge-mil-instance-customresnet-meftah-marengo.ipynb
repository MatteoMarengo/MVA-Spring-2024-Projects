{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7931873,"sourceType":"datasetVersion","datasetId":4451627}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["-----\n","----\n","# <b> DLMI Challenge </b>\n","# <b> MIL Instance </b>\n","# <b> Matteo MARENGO | matteo.marengo@ens-paris-saclay.fr </b>\n","# <b> Manal MEFTAH | manal.meftah@ens-paris-saclay.fr </b>\n"],"metadata":{"id":"O18e8bKs7gvA"}},{"cell_type":"markdown","source":["----\n","----\n","# <b> Import libraries </b>"],"metadata":{"id":"7sv04REU7gvC"}},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import balanced_accuracy_score\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from tqdm import tqdm\n","import numpy as np\n","from sklearn.metrics import f1_score, recall_score, precision_score\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"],"metadata":{"id":"oI1_HlwD7gvD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Dataset class </b>"],"metadata":{"id":"PokHPYRE7gvF"}},{"cell_type":"code","source":["class PatientImagesDataset(Dataset):\n","    def __init__(self, root_dir, annotations_file, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        # Read the annotations\n","        annotations = pd.read_csv(annotations_file)\n","        self.images = []\n","        self.labels = []\n","        # Assign labels to each image based on its bag\n","        for index, row in annotations.iterrows():\n","            img_folder = os.path.join(self.root_dir, str(row['ID']))\n","            for img_name in os.listdir(img_folder):\n","                if img_name.endswith('.jpg'):\n","                    self.images.append(os.path.join(img_folder, img_name))\n","                    self.labels.append(row['LABEL'])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.images[idx])\n","        if self.transform:\n","            image = self.transform(image)\n","        label = torch.tensor(int(self.labels[idx]))\n","        return image, label"],"metadata":{"id":"pmhpas2N7gvF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Custom ResNet and MIL class </b>"],"metadata":{"id":"i3kct3Sg7gvG"}},{"cell_type":"code","source":["class CustomResNet(nn.Module):\n","    def __init__(self, K):\n","        super(CustomResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, K, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(K)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.conv2 = self._make_layer(K, K, stride=1)\n","        self.conv3 = self._make_layer(K, 2*K, stride=2)\n","        self.conv4 = self._make_layer(2*K, 4*K, stride=2)\n","        self.conv5 = self._make_layer(4*K, 8*K, stride=2)\n","\n","\n","    def _make_layer(self, in_channels, out_channels, stride):\n","        layers = [\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels)\n","        ]\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","\n","        x = x.view(x.size(0), -1)\n","\n","        return x\n","\n","class MILModel(nn.Module):\n","    def __init__(self, K=64):\n","        super(MILModel, self).__init__()\n","        self.feature_extractor = CustomResNet(K)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(7 * 7 * 8 * K, 1024),\n","            nn.ReLU(True),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(True),\n","            nn.Dropout(0.5),\n","            nn.Linear(512, 128),\n","            nn.ReLU(True),\n","            nn.Linear(128, 1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.feature_extractor(x)  # Extract features from the image\n","        x = x.view(x.size(0), -1)  # Flatten the output for the classifier\n","        x = self.classifier(x)  # Classify the image\n","        return torch.sigmoid(x)\n"],"metadata":{"id":"w8DEdB1E7gvH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","dataset = PatientImagesDataset(root_dir='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/trainset', annotations_file='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/trainset/trainset_true.csv', transform=transform)\n","train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=dataset.labels)\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n","val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n","\n","train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler)\n","val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler)\n","\n","\n","# Initialize model, optimizer, and criterion\n","model = MILModel(K=64).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n","criterion = nn.BCELoss()\n","\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","val_f1_scores = []\n","val_recall_scores = []\n","val_precision_scores = []\n","\n","# Training loop\n","num_epochs = 150\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_loader_tqdm = tqdm(train_loader, desc=\"Training\")\n","    for images, labels in train_loader_tqdm:\n","        images = images.to(device)\n","        labels = labels.to(device).float().view(-1, 1)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        train_loader_tqdm.set_postfix({\"Train Loss\": f\"{loss.item():.4f}\"})\n","\n","    print(f\"Training Loss: {train_loss/len(train_loader)}\")\n","\n","    # Validation loop\n","    model.eval()\n","    val_loss = 0.0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        val_loader_tqdm = tqdm(val_loader, desc=\"Validation\")\n","        for images, labels in val_loader_tqdm:\n","            images = images.to(device)\n","            labels = labels.to(device).float().view(-1, 1)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            preds = outputs.round().cpu().numpy()\n","            all_preds.extend(preds.flatten().tolist())\n","            all_labels.extend(labels.cpu().numpy().flatten().tolist())\n","\n","    # Calculate validation metrics\n","    f1 = f1_score(all_labels, all_preds, average='binary')\n","    recall = recall_score(all_labels, all_preds, average='binary')\n","    precision = precision_score(all_labels, all_preds, average='binary')\n","    val_acc = balanced_accuracy_score(all_labels, all_preds)\n","\n","    # Store metrics for visualization or further analysis\n","    train_losses.append(train_loss / len(train_loader))\n","    val_losses.append(val_loss / len(val_loader))\n","    val_accuracies.append(val_acc)\n","    val_f1_scores.append(f1)\n","    val_recall_scores.append(recall)\n","    val_precision_scores.append(precision)\n","\n","    # Print validation metrics to monitor performance\n","    print(f'Epoch {epoch+1}/{num_epochs} - Training Loss: {train_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(val_loader):.4f}, Val Balanced Acc: {val_acc:.4f}, F1: {f1:.4f}, Recall: {recall:.4f}, Precision: {precision:.4f}')\n","\n","# Save model weights\n","torch.save(model.state_dict(), '/kaggle/working/model_MIL_Instance_Unbalanced.pth')\n","\n","# Plot training and validation metrics\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 3, 1)\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.legend()\n","plt.title('Losses')\n","plt.savefig('/kaggle/working/Train_Validation_Losses_MIL_Instance_Unbalanced.png')\n","\n","plt.subplot(1, 3, 2)\n","plt.plot(val_accuracies, label='Val Balanced Accuracy')\n","plt.legend()\n","plt.title('Balanced Accuracy')\n","plt.savefig('/kaggle/working/balanced_accuracy_MIL_Instance_Unbalanced.png')\n","\n","plt.subplot(1, 3, 3)\n","plt.plot(val_f1_scores, label='F1 Score')\n","plt.plot(val_recall_scores, label='Recall')\n","plt.plot(val_precision_scores, label='Precision')\n","plt.legend()\n","plt.title('Validation Metrics')\n","plt.savefig('/kaggle/working/metrics_MIL_Instance_Unbalanced.png')\n","\n","plt.show()\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2024-03-25T12:43:58.108417Z","iopub.execute_input":"2024-03-25T12:43:58.108743Z","iopub.status.idle":"2024-03-25T12:50:04.697197Z","shell.execute_reply.started":"2024-03-25T12:43:58.108716Z","shell.execute_reply":"2024-03-25T12:50:04.695658Z"},"trusted":true,"id":"y4eYrBar7gvI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Predict on the test set </b>"],"metadata":{"id":"CsDxbfS-7gvJ"}},{"cell_type":"code","source":["class PatientTestImagesDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.folders = [os.path.join(root_dir, o) for o in os.listdir(root_dir)\n","                        if os.path.isdir(os.path.join(root_dir,o))]\n","\n","        self.images = []\n","        self.patients = []\n","\n","        for folder in self.folders:\n","            patient_id = os.path.basename(folder)\n","            for img_name in os.listdir(folder):\n","                if img_name.endswith('.jpg'):\n","                    self.images.append(os.path.join(folder, img_name))\n","                    self.patients.append(patient_id)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = Image.open(self.images[idx])\n","        if self.transform:\n","            image = self.transform(image)\n","        patient_id = self.patients[idx]\n","        return image, patient_id\n","\n","test_dataset = PatientTestImagesDataset(root_dir='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/testset', transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","model.eval()\n","patient_predictions = {}\n","with torch.no_grad():\n","    for images, patient_ids in tqdm(test_loader, desc=\"Predicting Test Data\"):\n","        images = images.to(device)\n","        outputs = model(images)\n","        predictions = outputs.round().cpu().numpy()\n","\n","        for patient_id, prediction in zip(patient_ids, predictions):\n","            if patient_id not in patient_predictions:\n","                patient_predictions[patient_id] = []\n","            patient_predictions[patient_id].append(int(prediction))\n","\n","final_predictions = []\n","for patient_id, preds in patient_predictions.items():\n","    majority_class = round(sum(preds) / len(preds))\n","    final_predictions.append((patient_id, majority_class))\n","\n","df_predictions = pd.DataFrame(final_predictions, columns=['Id', 'Predicted'])\n","\n","df_predictions.to_csv('/kaggle/working/Predicted_Instance_Mil_CustomResNet_Unbalanced.csv', index=False)\n","\n","final_predictions = []\n","\n","## We add a threshold\n","\n","for patient_id, preds in patient_predictions.items():\n","    zero_class_percentage = preds.count(0) / len(preds)\n","    if zero_class_percentage > 0.25:\n","        predicted_class = 0  # Assign class 0 if more than 25% of the predictions are 0\n","    else:\n","        predicted_class = 1\n","    final_predictions.append((patient_id, predicted_class))\n","\n","df_predictions = pd.DataFrame(final_predictions, columns=['Id', 'Predicted'])\n","\n","df_predictions.to_csv('/kaggle/working/Predicted_Instance_Mil_CustomResNet_Balanced.csv', index=False)\n"],"metadata":{"execution":{"iopub.status.busy":"2024-03-25T12:54:28.654177Z","iopub.execute_input":"2024-03-25T12:54:28.655110Z","iopub.status.idle":"2024-03-25T12:55:00.012053Z","shell.execute_reply.started":"2024-03-25T12:54:28.655073Z","shell.execute_reply":"2024-03-25T12:55:00.011032Z"},"trusted":true,"id":"DpYJDsN87gvK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Balanced/Weighted Loss </b>"],"metadata":{"id":"tbGeGd7o7gvL"}},{"cell_type":"code","source":["# Model definition\n","class MILModel(nn.Module):\n","    def __init__(self, K=64):\n","        super(MILModel, self).__init__()\n","        self.feature_extractor = CustomResNet(K)\n","        #self.classifier = nn.Linear(7*7*8*K, 1)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(7 * 7 * 8 * K, 1024),\n","            nn.ReLU(True),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(True),\n","            nn.Dropout(0.5),\n","            nn.Linear(512, 128),\n","            nn.ReLU(True),\n","            nn.Linear(128, 1)\n","        )\n","\n","    def forward(self, x):\n","        embeddings = self.feature_extractor(x)  # Process each instance in the bag.\n","        embedding = embeddings.mean(dim=0, keepdim=True)  # fMEAN pooling over instances in the bag.\n","        output = self.classifier(embedding)\n","        #return output\n","        return torch.sigmoid(output)\n","\n","# Prepare dataset and dataloader\n","transform = transforms.Compose([transforms.Resize((224, 224)),\n","                                transforms.ToTensor()])\n","\n","dataset = PatientImagesDataset(root_dir='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/trainset', annotations_file='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/trainset/trainset_true.csv', transform=transform)\n","train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=dataset.annotations['LABEL'])\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n","val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n","\n","def custom_collate_fn(batch):\n","    bags, labels = zip(*batch)\n","    # Convert labels to a tensor.\n","    labels = torch.tensor(labels)\n","    return bags, labels\n","\n","# Update DataLoader initialization with custom collate function\n","train_loader = DataLoader(dataset, batch_size=1, sampler=train_sampler, collate_fn=custom_collate_fn)\n","val_loader = DataLoader(dataset, batch_size=1, sampler=val_sampler, collate_fn=custom_collate_fn)\n","\n","# Initialize model, optimizer, and criterion\n","model = MILModel(K=64).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n","# pos_weight = torch.tensor([4]).to(device)\n","#criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([0.25]).to(device))\n","criterion = nn.BCELoss()\n","\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","val_f1_scores = []\n","val_recall_scores = []\n","val_precision_scores = []\n","\n","# Training loop\n","num_epochs = 200\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_loader_tqdm = tqdm(train_loader, desc=\"Training\")\n","    for batch in train_loader_tqdm:\n","        bag, label = batch[0][0], batch[1]\n","        bag = bag.to(device)\n","        #print(bag.shape)\n","        #print(label)\n","        label = label.to(device)\n","        optimizer.zero_grad()\n","        output = model(bag)\n","        #print(output)\n","        loss = criterion(output[0], label.float())\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        train_loader_tqdm.set_postfix({\"Train Loss\": f\"{loss.item():.4f}\"})\n","\n","    print(f\"Training Loss: {train_loss/len(train_loader)}\")\n","\n","    # Validation loop\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    val_loss = 0.0\n","\n","    with torch.no_grad():\n","        val_loader_tqdm = tqdm(val_loader, desc=\"Validation\")\n","        for batch in val_loader_tqdm:\n","            bag, label = batch[0][0], batch[1]\n","            bag = bag.to(device)\n","            label = label.to(device)\n","            output = model(bag)\n","            #pred_output = torch.sigmoid(output)\n","\n","            loss = criterion(output[0], label.float())\n","            val_loss += loss.item()\n","            preds = output[0].round()\n","            print(preds)\n","            all_preds.extend(preds.cpu().numpy().flatten().tolist())\n","            all_labels.extend(label.cpu().numpy().flatten().tolist())\n","\n","    # Calculate validation metrics\n","    f1 = f1_score(all_labels, all_preds, average='binary')\n","    recall = recall_score(all_labels, all_preds, average='binary')\n","    precision = precision_score(all_labels, all_preds, average='binary')\n","\n","    val_acc = balanced_accuracy_score(all_labels, all_preds)\n","\n","    # Store metrics\n","    train_losses.append(train_loss/len(train_loader))\n","    val_losses.append(val_loss/len(val_loader))\n","    val_accuracies.append(val_acc)\n","    val_f1_scores.append(f1)\n","    val_recall_scores.append(recall)\n","    val_precision_scores.append(precision)\n","\n","    # Print validation metrics\n","    print(f'Validation F1 Score: {f1}')\n","    print(f'Validation Recall: {recall}')\n","    print(f'Validation Precision: {precision}')\n","\n","    val_acc = balanced_accuracy_score(all_labels, all_preds)\n","    print(f'Validation Loss: {val_loss/len(val_loader)}, Val Balanced Acc: {val_acc}')\n","\n","# Save model weights\n","torch.save(model.state_dict(), '/kaggle/working/model_MIL_Embedding_Unbalanced.pth')\n","\n","# Plot training and validation metrics\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 3, 1)\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.legend()\n","plt.title('Losses')\n","plt.savefig('/kaggle/working/Train_Validation_Losses_MIL_Embedding_Unbalanced.png')\n","\n","plt.subplot(1, 3, 2)\n","plt.plot(val_accuracies, label='Val Balanced Accuracy')\n","plt.legend()\n","plt.title('Balanced Accuracy')\n","plt.savefig('/kaggle/working/balanced_accuracy_MIL_Embedding_Unbalanced.png')\n","\n","plt.subplot(1, 3, 3)\n","plt.plot(val_f1_scores, label='F1 Score')\n","plt.plot(val_recall_scores, label='Recall')\n","plt.plot(val_precision_scores, label='Precision')\n","plt.legend()\n","plt.title('Validation Metrics')\n","plt.savefig('/kaggle/working/metrics_MIL_Embedding_Unbalanced.png')\n","\n","plt.show()"],"metadata":{"id":"1UbyU81C7gvM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> MIL INstance with attention pooling </b>"],"metadata":{"id":"AXs3vjQF7gvN"}},{"cell_type":"code","source":["# THE ATTENTION POOLING\n","class AttentionPooling(nn.Module):\n","    def __init__(self, in_features):\n","        super(AttentionPooling, self).__init__()\n","        self.attention_vector = nn.Parameter(torch.empty(in_features, dtype=torch.float32))\n","        nn.init.xavier_uniform_(self.attention_vector.unsqueeze(0))\n","\n","    def forward(self, x):\n","        # Compute attention scores and apply softmax\n","        attention_scores = torch.matmul(x, self.attention_vector)\n","        attention_weights = F.softmax(attention_scores, dim=0)\n","\n","        # Compute the weighted average\n","        weighted_features = x * attention_weights.unsqueeze(-1)\n","        pooled_features = weighted_features.sum(dim=0)\n","        return pooled_features\n","\n","class MILModel(nn.Module):\n","    def __init__(self, K=64):\n","        super(MILModel, self).__init__()\n","        #self.feature_extractor = CustomResNet(K)\n","        self.feature_extractor = VisionTransformer(2)\n","        self.attention_pooling = AttentionPooling(K*7*7*8)\n","        #self.classifier = nn.Linear(7*7*8*K, 1)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(7*7*8*K, 512),  # First linear layer\n","            nn.ReLU(),                # Non-linearity\n","            nn.Linear(512, 128),      # Second linear layer\n","            nn.ReLU(),                # Non-linearity\n","            nn.Linear(128, 1)         # Final layer to output\n","        )\n","\n","    def forward(self, x):\n","        embeddings = self.feature_extractor(x)\n","        #embedding = embeddings.mean(dim=0, keepdim=True)\n","        embedding = self.attention_pooling(embeddings)\n","        output = self.classifier(embedding)\n","        return output\n","        #return torch.sigmoid(output)\n","\n","# Prepare dataset and dataloader\n","transform = transforms.Compose([transforms.Resize((224, 224)),\n","                                transforms.ToTensor()])\n","\n","dataset = PatientImagesDataset(root_dir='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/trainset', annotations_file='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/trainset/trainset_true.csv', transform=transform)\n","train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=dataset.annotations['LABEL'])\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n","val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n","\n","# Custom collate function\n","def custom_collate_fn(batch):\n","    bags, labels = zip(*batch)\n","    labels = torch.tensor(labels)\n","    return bags, labels\n","\n","# Update DataLoader initialization with custom collate function\n","train_loader = DataLoader(dataset, batch_size=1, sampler=train_sampler, collate_fn=custom_collate_fn)\n","val_loader = DataLoader(dataset, batch_size=1, sampler=val_sampler, collate_fn=custom_collate_fn)\n","\n","# Initialize model, optimizer, and criterion\n","model = MILModel(K=64).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","# pos_weight = torch.tensor([4]).to(device)\n","criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([4]).to(device))\n","#criterion = nn.BCELoss()\n","\n","# Initialize learning rate scheduler\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20000, gamma=0.1)\n","\n","\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","val_f1_scores = []\n","val_recall_scores = []\n","val_precision_scores = []\n","\n","# Training loop\n","num_epochs = 150\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_loader_tqdm = tqdm(train_loader, desc=\"Training\")\n","    for batch in train_loader_tqdm:\n","        bag, label = batch[0][0], batch[1]\n","        bag = bag.to(device)\n","        #print(bag.shape)\n","        #print(label)\n","        label = label.to(device)\n","        optimizer.zero_grad()\n","        output = model(bag)\n","        #print(output[0])\n","        loss = criterion(output, label.float())\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        train_loader_tqdm.set_postfix({\"Train Loss\": f\"{loss.item():.4f}\"})\n","\n","    print(f\"Epoch {epoch+1}, Training Loss: {train_loss/len(train_loader)}\")\n","    lr_scheduler.step()\n","\n","    # Validation loop\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    val_loss = 0.0\n","\n","    with torch.no_grad():\n","        val_loader_tqdm = tqdm(val_loader, desc=\"Validation\")\n","        for batch in val_loader_tqdm:  `\n","            bag, label = batch[0][0], batch[1]\n","            bag = bag.to(device)\n","            label = label.to(device)\n","            output = model(bag)\n","            pred_output = torch.sigmoid(output)\n","\n","            loss = criterion(output, label.float())\n","            val_loss += loss.item()\n","            preds = pred_output[0].round()\n","            all_preds.extend(preds.cpu().numpy().flatten().tolist())\n","            all_labels.extend(label.cpu().numpy().flatten().tolist())\n","\n","    # Calculate validation metrics\n","    f1 = f1_score(all_labels, all_preds, labels=[0, 1], average='binary')\n","    recall = recall_score(all_labels, all_preds, labels=[0, 1], average='binary')\n","    precision = precision_score(all_labels, all_preds, labels=[0, 1], average='binary')\n","\n","    val_acc = balanced_accuracy_score(all_labels, all_preds)\n","\n","    # Store metrics\n","    train_losses.append(train_loss/len(train_loader))\n","    val_losses.append(val_loss/len(val_loader))\n","    val_accuracies.append(val_acc)\n","    val_f1_scores.append(f1)\n","    val_recall_scores.append(recall)\n","    val_precision_scores.append(precision)\n","\n","    # Print validation metrics\n","    print(f'Validation F1 Score: {f1}')\n","    print(f'Validation Recall: {recall}')\n","    print(f'Validation Precision: {precision}')\n","\n","    val_acc = balanced_accuracy_score(all_labels, all_preds)\n","    print(f'Validation Loss: {val_loss/len(val_loader)}, Val Balanced Acc: {val_acc}')\n","\n","# Save model weights\n","torch.save(model.state_dict(), '/kaggle/working/model_weights.pth')\n","\n","# Plot training and validation metrics\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 3, 1)\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.legend()\n","plt.title('Losses')\n","plt.savefig('/kaggle/working/train_val_loss.png')\n","\n","plt.subplot(1, 3, 2)\n","plt.plot(val_accuracies, label='Val Balanced Accuracy')\n","plt.legend()\n","plt.title('Balanced Accuracy')\n","plt.savefig('/kaggle/working/val_balanced_accuracy.png')\n","\n","plt.subplot(1, 3, 3)\n","plt.plot(val_f1_scores, label='F1 Score')\n","plt.plot(val_recall_scores, label='Recall')\n","plt.plot(val_precision_scores, label='Precision')\n","plt.legend()\n","plt.title('Validation Metrics')\n","plt.savefig('/kaggle/working/validation_metrics.png')\n","\n","plt.show()"],"metadata":{"id":"9LJ0xnmp7gvO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Predict the test set </b>"],"metadata":{"id":"xSh_qgyn7gvP"}},{"cell_type":"code","source":["test_dataset = PatientImagesDataset(root_dir='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/testset', annotations_file = '/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/testset/testset_data.csv', transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=custom_collate_fn)\n","\n","model.eval()\n","\n","predictions_list = []\n","\n","with torch.no_grad():\n","    for batch in test_loader:\n","        bag, _ = batch[0][0], batch[1]\n","        print(bag.shape)\n","        bag = bag.to(device)\n","        output = model(bag)\n","        predicted_label = output[0].cpu().numpy()\n","        print(predicted_label.round())\n","\n","        predictions_list.append(int(predicted_label.round()))\n","        #predictions_list.extend(output.cpu().numpy())\n","\n","df = pd.read_csv(\"/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/testset/testset_data.csv\")\n","\n","submission_df = pd.DataFrame({\n","    'Id': df['ID'],\n","    'Predicted': predictions_list\n","})\n","\n","submission_df.to_csv('/kaggle/working/MIL_Embedding_Unbalanced_CUSTOM_ResNet.csv', index=False)\n","print(submission_df.head())\n"],"metadata":{"id":"_wYoP1Cp7gvP"},"execution_count":null,"outputs":[]}]}