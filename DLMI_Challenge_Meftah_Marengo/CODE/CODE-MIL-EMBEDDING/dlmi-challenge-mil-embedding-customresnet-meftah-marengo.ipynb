{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":7931873,"datasetId":4451627,"databundleVersionId":8040299}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["----\n","----\n","# <b> Challenge DLMI </b>\n","# <b> Multi-Instance Learning Embedding </b>\n","# <b> Matteo MARENGO | matteo.marengo@ens-paris-saclay.fr</b>\n","# <b> Manal MEFTHA | manal.meftah@ens-paris-saclay.fr </b>"],"metadata":{"id":"iDaMiLU28MoW"}},{"cell_type":"markdown","source":["----\n","----\n","# <b> Import Libraries </b>"],"metadata":{"id":"-OqdMH3u8MoX"}},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import balanced_accuracy_score\n","import pandas as pd\n","from PIL import Image\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score, recall_score, precision_score"],"metadata":{"id":"53w-nq8O8MoY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Define the device </b>"],"metadata":{"id":"Psath3q08Moa"}},{"cell_type":"code","source":["# Check for GPU availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"],"metadata":{"id":"OsLPMDso8Moa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Define the Dataset Class </b>"],"metadata":{"id":"-6uL2SRw8Mob"}},{"cell_type":"code","source":["# Dataset class\n","class PatientImagesDataset(Dataset):\n","    def __init__(self, root_dir, annotations_file, transform=None):\n","        self.root_dir = root_dir\n","        self.annotations = pd.read_csv(annotations_file)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, idx):\n","        img_folder = os.path.join(self.root_dir, str(self.annotations.iloc[idx, 0]))\n","        images = [os.path.join(img_folder, file) for file in os.listdir(img_folder) if file.endswith('.jpg')]\n","        bags = []\n","        for img_name in images:\n","            image = Image.open(img_name)\n","            if self.transform:\n","                image = self.transform(image)\n","            bags.append(image)\n","        bags = torch.stack(bags)\n","        # second column of the dataframe - the label of the bag\n","        labels = torch.tensor(int(self.annotations.iloc[idx, 1]))\n","        return bags, labels"],"metadata":{"id":"oTVew8228Moc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Define the CustomResNet </b>"],"metadata":{"id":"-LS8TiGj8Moc"}},{"cell_type":"code","source":["class CustomResNet(nn.Module):\n","    def __init__(self, K):\n","        super(CustomResNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, K, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(K)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","        self.conv2 = self._make_layer(K, K, stride=1)\n","        self.conv3 = self._make_layer(K, 2*K, stride=2)\n","        self.conv4 = self._make_layer(2*K, 4*K, stride=2)\n","        self.conv5 = self._make_layer(4*K, 8*K, stride=2)\n","\n","\n","    def _make_layer(self, in_channels, out_channels, stride):\n","        layers = [\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels)\n","        ]\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","\n","        x = x.view(x.size(0), -1)\n","\n","        return x"],"metadata":{"id":"57-TWmQ-8Mod"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Define the MIL model </b>"],"metadata":{"id":"lhIzwBbI8Mog"}},{"cell_type":"code","source":["class MILModel(nn.Module):\n","    def __init__(self, K=64):\n","        super(MILModel, self).__init__()\n","        self.feature_extractor = CustomResNet(K)\n","        self.classifier = nn.Linear(7*7*8*K, 1)\n","\n","    def forward(self, x):\n","        embeddings = self.feature_extractor(x)\n","        embedding = embeddings.mean(dim=0, keepdim=True)\n","        output = self.classifier(embedding)\n","        #return output\n","        return torch.sigmoid(output)"],"metadata":{"id":"fE3DhrCX8Moh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Train the model </b>"],"metadata":{"id":"89GbjMBA8Moi"}},{"cell_type":"code","source":["transform = transforms.Compose([transforms.Resize((224, 224)),\n","                                transforms.ToTensor()])\n","\n","dataset = PatientImagesDataset(root_dir='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/trainset', annotations_file='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/trainset/trainset_true.csv', transform=transform)\n","train_indices, val_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=dataset.annotations['LABEL'])\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n","val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n","\n","def custom_collate_fn(batch):\n","    bags, labels = zip(*batch)\n","    labels = torch.tensor(labels)\n","    return bags, labels\n","\n","train_loader = DataLoader(dataset, batch_size=1, sampler=train_sampler, collate_fn=custom_collate_fn)\n","val_loader = DataLoader(dataset, batch_size=1, sampler=val_sampler, collate_fn=custom_collate_fn)\n","\n","model = MILModel(K=64).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n","criterion = nn.BCELoss() # not balanced loss for this case\n","\n","train_losses = []\n","val_losses = []\n","val_accuracies = []\n","val_f1_scores = []\n","val_recall_scores = []\n","val_precision_scores = []\n","\n","num_epochs = 150\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_loader_tqdm = tqdm(train_loader, desc=\"Training\")\n","    for batch in train_loader_tqdm:\n","        bag, label = batch[0][0], batch[1]\n","        bag = bag.to(device)\n","        #print(bag.shape)\n","        #print(label)\n","        label = label.to(device)\n","        optimizer.zero_grad()\n","        output = model(bag)\n","        #print(output)\n","        loss = criterion(output[0], label.float())\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        train_loader_tqdm.set_postfix({\"Train Loss\": f\"{loss.item():.4f}\"})\n","\n","    print(f\"Training Loss: {train_loss/len(train_loader)}\")\n","\n","    # Validation loop\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    val_loss = 0.0\n","\n","    with torch.no_grad():\n","        val_loader_tqdm = tqdm(val_loader, desc=\"Validation\")\n","        for batch in val_loader_tqdm:\n","            bag, label = batch[0][0], batch[1]\n","            bag = bag.to(device)\n","            label = label.to(device)\n","            output = model(bag)\n","            loss = criterion(output[0], label.float())\n","            val_loss += loss.item()\n","\n","            preds = output[0].round()\n","            all_preds.extend(preds.cpu().numpy().flatten().tolist())\n","            all_labels.extend(label.cpu().numpy().flatten().tolist())\n","\n","    f1 = f1_score(all_labels, all_preds, average='binary')\n","    recall = recall_score(all_labels, all_preds, average='binary')\n","    precision = precision_score(all_labels, all_preds, average='binary')\n","    val_acc = balanced_accuracy_score(all_labels, all_preds)\n","\n","    train_losses.append(train_loss/len(train_loader))\n","    val_losses.append(val_loss/len(val_loader))\n","    val_accuracies.append(val_acc)\n","    val_f1_scores.append(f1)\n","    val_recall_scores.append(recall)\n","    val_precision_scores.append(precision)\n","\n","\n","    print(f'Validation F1 Score: {f1}')\n","    print(f'Validation Recall: {recall}')\n","    print(f'Validation Precision: {precision}')\n","\n","    val_acc = balanced_accuracy_score(all_labels, all_preds)\n","    print(f'Validation Loss: {val_loss/len(val_loader)}, Val Balanced Acc: {val_acc}')\n","\n","# Save model weights\n","torch.save(model.state_dict(), '/kaggle/working/model_weights.pth')\n","\n","# Plot training and validation metrics\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 3, 1)\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.legend()\n","plt.title('Losses')\n","\n","plt.subplot(1, 3, 2)\n","plt.plot(val_accuracies, label='Val Balanced Accuracy')\n","plt.legend()\n","plt.title('Balanced Accuracy')\n","\n","plt.subplot(1, 3, 3)\n","plt.plot(val_f1_scores, label='F1 Score')\n","plt.plot(val_recall_scores, label='Recall')\n","plt.plot(val_precision_scores, label='Precision')\n","plt.legend()\n","plt.title('Validation Metrics')\n","\n","plt.show()"],"metadata":{"id":"Rc693fVQ8Moj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["----\n","----\n","# <b> Predict the test set and save it as a dataframe </b>"],"metadata":{"id":"ON1uj8GR8Mok"}},{"cell_type":"code","source":["test_dataset = PatientImagesDataset(root_dir='/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/testset', annotations_file = '/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/testset/testset_data.csv', transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=custom_collate_fn)\n","\n","model.eval()\n","\n","predictions_list = []\n","\n","with torch.no_grad():\n","    for batch in test_loader:\n","        bag, _ = batch[0][0], batch[1]\n","        print(bag.shape)\n","        bag = bag.to(device)\n","        output = model(bag)\n","        predicted_label = int(round(output.cpu().numpy()[0][0]))\n","        predictions_list.append(predicted_label)\n","\n","df = pd.read_csv(\"/kaggle/input/dlmi-mms-data/dlmi-lymphocytosis-classification/testset_data.csv\")\n","\n","submission_df = pd.DataFrame({\n","    'Id': df['ID'],\n","    'Predicted': predictions_list\n","})\n","\n","submission_df.to_csv('/kaggle/working/custom_Resnet.csv', index=False)\n","print(submission_df.head())\n"],"metadata":{"id":"zTs84jy08Mol"},"execution_count":null,"outputs":[]}]}